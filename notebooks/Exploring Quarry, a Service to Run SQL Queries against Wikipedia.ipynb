{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: Raymond Yee ([@rdhyee](https://twitter.com/rdhyee)) <br/>\n",
    "last edit: 2017.07.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Care about Quarry?\n",
    "\n",
    "After expending considerable effort using the Wikipedia API to assemble a database of user edit metadata in support of the work reported \"[Gender Differences in Wikipedia Editing](https://dl.acm.org/citation.cfm?doid=2038558.2038561)\" (a [prize-winning short paper](http://www.wikisym.org/2011/09/21/best-paper-winners-for-wikisym-2011/comment-page-1/) for [WikiSym 2011](http://www.wikisym.org/ws2011/start.html)), I've been long intrigued by having direct access to the database behind Wikipedia.  With direct database access, there would no need to accumulate data by polling the API, a laborious and error-prone process used for the paper.   Just [sign up for an account](https://wikitech.wikimedia.org/wiki/Help:Getting_Started#Create_a_User_Account) on [Wikimedia Labs](https://wikitech.wikimedia.org/wiki/Help:FAQ#What_is_Wikimedia_Labs.3F), and [connect to the live database replicas](https://wikitech.wikimedia.org/wiki/Help:Tool_Labs/Database#Connecting_to_the_database_replicas).  It helps to understand the [Mediawiki database layout](https://www.mediawiki.org/wiki/Manual:Database_layout) and to study [example MySQL queries that can be run on the replicas](https://wikitech.wikimedia.org/wiki/Nova_Resource:Tools/Shared_Resources/MySQL_queries).  Undoubtedly, there is a learning curve; there's lot of documentation out there but I've found it a chore to make sense of it all.  (If you get confused, don't forget to ask for help on the [Labs-l Mailing List](https://lists.wikimedia.org/mailman/listinfo/labs-l) or the [wikimedia labs IRC channel](https://webchat.freenode.net/?channels=#wikimedia-labs).\n",
    "\n",
    "In my self-education about the Wikipedia databases, I've been particularly happy to find [Quarry](http://quarry.wmflabs.org), a web application (currently in beta), that allows one to \"[r]un SQL queries against Wikipedia & other databases from your browser\".  You can run SQL queries and see the results in the browser, download results, and also easily share your queries and results with others. You can also see what queries other people have run, from which you can presumably learn much.  (Finally, you don't need a shell account on Wikimedia Labs to use the service.)\n",
    "\n",
    "I've been enjoying Quarry a lot, but wanted to integrated its functionality with other software.  Specifically, I wanted to integrate work I'm doing on Quarry with the [IPython/Jupyter notebook](https://en.wikipedia.org/wiki/IPython). To begin with, it'd be convenient to be able to programmatically access the output from queries. It turns out that you can make use of an implicit Quarry API to read not only the output data of a query but associated metadata, including the query SQL itself, the author, title, and date of execution.  Some things I describe here:\n",
    "\n",
    "* What queries have I made at Quarry?  \n",
    "* Specifically, can one get at which ones are published and drafts?  \n",
    "* Can one get data on specific runs?  \n",
    "* What queries are starred?\n",
    "\n",
    "As I began to write integration with Quarry and surface my own work on Quarry, I then start to explore the question of what other people are doing on Quarry.  Such questions as:\n",
    "\n",
    "* What users are there?  Can I get the same info for those folks?\n",
    "* What popular queries are there?\n",
    "* Can we understand the flow of use -- are people learning from each other?\n",
    "\n",
    "This notebook shows some preliminary work in that area.\n",
    "\n",
    "## How to learn more about Quarry\n",
    "\n",
    "BTW, don't miss the [main documentation page for Quarry](https://meta.wikimedia.org/wiki/Research:Quarry) and [three-part Wikiresearch webinar series](https://meta.wikimedia.org/wiki/Grants:Evaluation/Wikiresearch_webinars), which includes videos ( [1](https://www.youtube.com/watch?v=IjvZJ6joQD4#t=12), [2](https://www.youtube.com/watch?v=V5Te4_mQq8Y), [3](https://www.youtube.com/watch?v=CcNoDplKqTc)) with some coverage on using Quarry.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from itertools import (islice, chain)\n",
    "import re\n",
    "import time\n",
    "from collections import (Counter, OrderedDict)\n",
    "\n",
    "# writing for eventual Python 2/3 compatability \n",
    "\n",
    "try:\n",
    "    from urllib.parse import urlencode\n",
    "except ImportError:\n",
    "    from urllib import urlencode\n",
    "        \n",
    "import requests\n",
    "\n",
    "from lxml.html import fromstring, parse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import (DataFrame, Series)\n",
    "\n",
    "from IPython.display import (display, HTML, Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with results from a specific query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a [big fan of the music of J. S. Bach](https://web.archive.org/web/20030414021116/http://iu.berkeley.edu/rdhyee/cosmicbach), I'm also very interested in the history of the [English Wikipedia page for Johann Sebastian Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach). How did the article develop over the years?  When was it most actively edited?\n",
    "\n",
    "For a simple question to answer using Quarry, I wanted to compute [the number of revisions by year for Johann_Sebastian_Bach in enwiki](http://quarry.wmflabs.org/query/3659).  \n",
    "\n",
    "The easiest workflow with which to begin is to refine a query on Quarry and then [download the resultset](https://meta.wikimedia.org/wiki/Research:Quarry#Downloading_a_resultset).   That is, for a recent run, I could analyze the output by first downloading the JSON-formatted data from <http://quarry.wmflabs.org/run/24183/output/0/json?download=true>.  But if I were to run the query again, the URL for the output changes again because the run number changes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python function to download information about a Quarry query\n",
    "\n",
    "For the purposes of analyzing the output from queries in Quarry, instead of manually downloading the output of a Quarry query (and the accompanying metadata), it is ultimately easier to programatically obtain that output.  \n",
    "\n",
    "Through a combination of reverse engineering Quarry, greatly helped the [open availability of source code for Quarry](https://github.com/wikimedia/analytics-quarry-web), I wrote the following Python functions to obtain the output and to display that output in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarry_result(query_id, rev_id=None, result_format='json'):\n",
    "    \"\"\"\n",
    "    returns a dict {'status', 'output', 'query_meta' 'latest_run', 'latest_rev'} for a query_id on quarry.wmflabs.org\n",
    "    \"\"\"\n",
    "    \n",
    "    BASE_URL = \"http://quarry.wmflabs.org\"\n",
    "    \n",
    "    # get the metadata for the query\n",
    "    # https://github.com/wikimedia/analytics-quarry-web/blob/e2346c5ec47d63f9514b8aef9190211fa5ff0e45/quarry/web/app.py#L402\n",
    "    url = BASE_URL + \"/query/{0}/meta\".format(query_id)\n",
    "    \n",
    "    try: \n",
    "        query_meta = requests.get(url).json()\n",
    "        status = query_meta['latest_run']['status']\n",
    "        latest_run_id = query_meta['latest_run']['id']\n",
    "        latest_rev_id = query_meta['latest_rev']['id']\n",
    "\n",
    "        # if status is 'complete' and return_output is True,\n",
    "        # grab the results -- unless result_format is None\n",
    "        # https://github.com/wikimedia/analytics-quarry-web/blob/e2346c5ec47d63f9514b8aef9190211fa5ff0e45/quarry/web/app.py#L350\n",
    "\n",
    "        if (status == 'complete' and result_format is not None):\n",
    "            # TO DO: figure out whether 0 should be a variable\n",
    "            # re: https://github.com/wikimedia/analytics-quarry-web/blob/e2346c5ec47d63f9514b8aef9190211fa5ff0e45/quarry/web/app.py#L351\n",
    "            # 0 is default value for resultset_id \n",
    "            url = BASE_URL + \"/run/{0}/output/0/{1}\".format(latest_run_id, result_format)\n",
    "            if result_format == 'json':\n",
    "                output = requests.get(url).json()\n",
    "            else:\n",
    "                output = requests.get(url).text\n",
    "        else:\n",
    "            output = None\n",
    "\n",
    "        return {'query_meta':query_meta, \n",
    "                'status': status,\n",
    "                'latest_run': latest_run_id,\n",
    "                'latest_rev': latest_rev_id,\n",
    "                'output': output\n",
    "               }\n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "# assume for now latest rev id same as latest run id.\n",
    "# 'status':query_meta[\"status\"]\n",
    "        \n",
    "def display_objs_for_q_result(q):\n",
    "    \"\"\"\n",
    "    returns IPython/Jupyter display object to describe query metadata and SQL content\n",
    "    (first pass)\n",
    "    \"\"\"\n",
    "\n",
    "    description = q['query_meta']['query']['description']\n",
    "    if description is None:\n",
    "        description = \"\"\n",
    "        \n",
    "    return ( HTML(\"<b>{0}</b>\".format(q['query_meta']['query']['title'])),\n",
    "             HTML(\"<p>id: {0} ({1})</p>\".format(q['query_meta']['query']['id'], \n",
    "                                                        q['query_meta']['query']['timestamp'])),\n",
    "             HTML(\"<p>{0}</p>\".format(description)),\n",
    "             Markdown(\"\"\"```sql\\n{0}\\n```\"\"\".format(q['query_meta']['latest_rev']['sql']))\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to retrieve and display the metadata for the query `3659` <http://quarry.wmflabs.org/query/3659>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = quarry_result(3659, result_format='json')\n",
    "display(*display_objs_for_q_result(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the output from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the output into a [pandas DataFrame](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(q['output']['rows'], columns=['year', 'count'])\n",
    "df.set_index(keys='year', inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bar chart of the revision counts for the Bach article by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar', title=\"revision counts for JSB article vs year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart alone brings up many questions for future exploration.  Why is there a large amount of activity between 2005 to 2007, followed by a dramatic decrease in 2008?  Did activity in authorship about Bach-related articles decline only for [Johann Sebastian Bach - Wikipedia, the free encyclopedia](http://en.wikipedia.org/wiki/Johann_Sebastian_Bach) alone or was there movement in authorship to related articles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all queries for a given username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query I wrote about Bach was only one of the queries I wrote on Quarry.  Once I could programmatically retrieve a single query, I wanted to interact with all the queries that I had created. To that end, I wrote `user_queries` to retrieve all the queries for a given user by scraping the profile page for a given user.  For example, <http://quarry.wmflabs.org/RaymondYee> has all the queries for the user `RaymondYee`.\n",
    "\n",
    "(I was hoping that the queries would be available to some type of JSON format, but I couldn't find such a source.  The [source code for Quarry](https://github.com/wikimedia/analytics-quarry-web/blob/e2346c5ec47d63f9514b8aef9190211fa5ff0e45/quarry/web/app.py#L154) confirms my suspicion that I need to scrape the profile page for a given user.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of queries\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "query_type_headers = OrderedDict([\n",
    "        ('published', 'Published queries'),\n",
    "        ('draft', 'Draft Queries'),\n",
    "        ('starred', 'Starred Queries')\n",
    "    ])\n",
    "\n",
    "\n",
    "def user_queries(username):\n",
    "    \"\"\"\n",
    "    get all queries for a user\n",
    "    e.g., parse http://quarry.wmflabs.org/RaymondYee\n",
    "    \"\"\"\n",
    "    \n",
    "    url = u\"http://quarry.wmflabs.org/{0}\".format(username)\n",
    "    r = requests.get(url)\n",
    "    page = requests.get(url).content.decode(\"UTF-8\")\n",
    "    doc = fromstring(page)\n",
    "    \n",
    "    # xpath expressions correlate with template\n",
    "    # https://github.com/wikimedia/analytics-quarry-web/blob/e2346c5ec47d63f9514b8aef9190211fa5ff0e45/quarry/web/templates/user.html\n",
    "    \n",
    "    # number of queries\n",
    "    queries = dict()\n",
    "    queries['num_queries'] =int(doc.xpath('//*[@class=\"user-stat\"]/h2/text()')[0])\n",
    "    \n",
    "\n",
    "    # loop through all the query types\n",
    "    for (qtype, qheader) in query_type_headers.items():\n",
    "        q_elements = doc.xpath('//h3[contains(text(),\"{0}\")][1]/following-sibling::ul[1]/li/a'.format(qheader))\n",
    "        q_results = []\n",
    "        for q in q_elements:\n",
    "            q_id = int(q.attrib['href'].split('/')[-1])\n",
    "            #result = quarry_result(q_id, result_format=None)\n",
    "            q_results.append( (q_id, q.text))\n",
    "        queries[qtype] = q_results\n",
    "        \n",
    "    return queries\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now retrieve my queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq = user_queries('RaymondYee')\n",
    "uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting a bit more work, we can make it easier to jump back to the original queries on Quarry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_display = \"\"\n",
    "queries_display += \"<p>number of queries: {0}</p>\".format(uq['num_queries'] )\n",
    "\n",
    "for (qtype, qheader) in query_type_headers.items():\n",
    "    queries_display += \"<b>{0}</b><br/>\".format(qheader)\n",
    "    for (q_id, q_title) in uq[qtype]:\n",
    "        queries_display += \"<div>{0} <a href='http://quarry.wmflabs.org/query/{0}'>{1}</a></div>\".format(q_id, q_title)\n",
    "    queries_display += \"<br/>\"\n",
    "    \n",
    "HTML(queries_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out all the SQL for the queries too.  Here's the description and SQL for my published and draft queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ry_results = [quarry_result(q_id, result_format=None) \n",
    "    for q_id in chain([q_id for (q_id, title) in uq['published']],\n",
    "                      [q_id for (q_id, title) in uq['draft']])\n",
    "              ]\n",
    "\n",
    "# the following way to display the results is a bit opaque and should be rewritten\n",
    "display(*list(chain(*[display_objs_for_q_result(r) for r in ry_results if not isinstance(r, Exception)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problematic queries\n",
    "# https://quarry.wmflabs.org/query/{q_id/}meta\n",
    "\n",
    "try:\n",
    "    from itertools import izip as zip\n",
    "except:\n",
    "    pass\n",
    "\n",
    "q_ids = list(chain([q_id for (q_id, title) in uq['published']],\n",
    "                      [q_id for (q_id, title) in uq['draft']]))\n",
    "\n",
    "[(id_) for (id_,r) in zip(q_ids, ry_results) if isinstance(r, Exception)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the next steps I'd want to pursue is to figure out how to programmatically write to Quarry, for example, formulate queries in Python and then send them to Qurray.  As a Wikimedia Lab user, I'd want to be able to move queries between Quarry and the job submission facility on the Labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing queries of all Quarry users collectively\n",
    "\n",
    "\n",
    "A major part of the appeal of Quarry is that you are part of a community of users creating queries.  I personally wanted to understand what others are doing on Quarry. \n",
    "\n",
    "To satisfy my curiosity, I decided to scrape the [Recent Queries](http://quarry.wmflabs.org/query/runs/all) page for a list of queries and their creators by writing `runs_list`.  The function `runs_list` will loop all the queries by paging through the entire history available on [Recent Queries](http://quarry.wmflabs.org/query/runs/all).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_info_or_text(td):\n",
    "    anchors = td.xpath('a')\n",
    "    if anchors:\n",
    "        #if anchor text in form of \"/query/query_id\", return just query_id\n",
    "        href = anchors[0].attrib['href']\n",
    "        query_search = re.search(\"/query/(\\d+)\", href)\n",
    "        if query_search:\n",
    "            return (int(query_search.group(1)), anchors[0].text )\n",
    "        else:\n",
    "            return (href, anchors[0].text )\n",
    "    else:\n",
    "        return td.text\n",
    "    \n",
    "def filter_none(d):\n",
    "    \"\"\"\n",
    "    return dict d without any items with None for value\n",
    "    \"\"\"\n",
    "    return dict([(k,v) for (k,v) in d.items() if v is not None])\n",
    "\n",
    "def runs_list(limit=None, from_=None, _sleep=0):\n",
    "    \"\"\"\n",
    "    Generator for all the queries on http://quarry.wmflabs.org/query/runs/all\n",
    "    \"\"\"\n",
    "    \n",
    "    url = (\"http://quarry.wmflabs.org/query/runs/all?\" +\n",
    "            urlencode(filter_none({'from':from_, 'limit':limit})))    \n",
    "    more_pages = True\n",
    "\n",
    "    while more_pages:\n",
    "\n",
    "        r = requests.get(url)\n",
    "        page = requests.get(url).content.decode(\"UTF-8\")\n",
    "        doc = fromstring(page)\n",
    "\n",
    "        # grab headers\n",
    "        headers = [th.text for th in doc.xpath(\"//th\")]\n",
    "        \n",
    "        # yield rows\n",
    "        for tr in doc.xpath(\"//tr[td]\"):\n",
    "            yield [anchor_info_or_text(td) for td in tr]\n",
    "        \n",
    "        # next link\n",
    "        next_links = doc.xpath('//li[@class=\"next\"]/a')\n",
    "        if next_links:\n",
    "            url = (\"http://quarry.wmflabs.org/query/runs/all?\" +\n",
    "                 next_links[0].attrib['href'])\n",
    "        else:\n",
    "            more_pages = False\n",
    "            \n",
    "        time.sleep(_sleep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scrape the pages.  As of 2015-05-30, there are few enough queries for me to practically get all the pages returned by Quarry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"time of analysis:\", datetime.datetime.utcnow().isoformat(), \"\\n\")\n",
    "queries = []\n",
    "\n",
    "# loop and print out which row we're on\n",
    "\n",
    "for (i, item) in enumerate(islice(runs_list(_sleep=0.5), None)):\n",
    "    print(\"\\r {0}\".format(i), end=\"\")\n",
    "    queries.append( (item[0][0], item[0][1], item[1][1], item[2], item[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the last five results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(queries, columns=['id', 'title', 'creator','status', 'time'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many queries records belong to me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.creator=='RaymondYee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique query identifiers and creators are there in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique ids\n",
    "\n",
    "len(df.id.unique()), len(df.creator.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am surprised such a small number of unique queries.  It's possible my code has a bug that causes me to miss many queries.  Alternative, Quarry might only return a limited selection.  (*To figure out.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through users to accumlate data on all user queries\n",
    "# on the way to computing most starred query\n",
    "\n",
    "queries_by_user = dict()\n",
    "\n",
    "for (i, username) in enumerate(islice(df.creator.unique(),None)):\n",
    "    print (\"\\r {0}\".format(i), end=\"\")\n",
    "    queries_by_user[username] = user_queries(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the queries that have been starred by others and the number of stars they have received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at what starred\n",
    "\n",
    "starred_q = Counter()\n",
    "\n",
    "for (u, d) in queries_by_user.items():\n",
    "    for q in d['starred']:\n",
    "        starred_q.update([q])    \n",
    "\n",
    "starred_q_display = \"\"\n",
    "\n",
    "for (q, count) in starred_q.most_common():\n",
    "    starred_q_display += u\"<div><a href='http://quarry.wmflabs.org/query/{0}'>{1}</a>: {2}</div>\".format(q[0],q[1],count)\n",
    "\n",
    "HTML(starred_q_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Next Steps\n",
    "\n",
    "There are lot of other aspects of Quarry to explore, not to mention the Wikimedia databases themselves!  Some ideas are:\n",
    "\n",
    "* compare SQL code among all the queries.  What queries are similar to each other?\n",
    "* write Python functions to write jobs directly to Quarry.\n",
    "* move jobs between Quarry and the job submission system on the Wikimedia Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
